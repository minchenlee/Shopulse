# **Shopulse**  

## **ğŸ“Œ Overview**  
Shopulse is a research-driven **e-commerce prototype** developed as part of the thesis **[An Explorative Study on User Behaviors with LLM-powered CUI and with GUI](https://tdr.lib.ntu.edu.tw/handle/123456789/94361)**. The project explores the impact of **Conversational User Interfaces (CUI), Graphical User Interfaces (GUI), and Hybrid UIs** on user experience in online shopping.  

ğŸ”— **[Jump to the Demo](#-demo)**  

## **ğŸš€ Features**  
### **AI-Assisted Product Interaction**
- **Conversational UI**: Integrates an AI chatbot (OpenAIâ€™s Assistant API) to help users find relevant products, explain technical details, and compare multiple items.
- **Hybrid UI**: A dual-pane layout with AI chat on the left and product listings on the right, where the right panel dynamically updates with product details, seamlessly integrating AI-driven assistance with a familiar e-commerce browsing experience.

### **Real-Time Communication**
- **Server-Sent Events (SSE)**: Implements live chat updates to keep interactions responsive without constant page reloading.
- **Context-Aware Responses**: The chatbot refines its suggestions and explanations based on conversation history and user inputs.

### **Product Data Collection**
- **Web Scraper (Puppeteer)**: Collects product information from Amazon and Walmart, storing the data in MongoDB.
- **Search & Filtering**: Offers keyword-based and chatbot-driven search, along with basic filtering options for user convenience.

### **Deployment & Infrastructure**
- **Infrastructure as Code (Terraform)**: Automates resource provisioning and management, making deployments more consistent and easier to maintain.
- **AWS Integration**: Utilizes AWS EC2, CloudFront, S3, and ELB for hosting, content delivery, and load balancing.

### **User Testing & Feedback**
- **Tested by 106 Users**: While not a large-scale commercial release, the system was tried by a diverse group of participants. Feedback indicated general ease of use and appreciation for the option to interact via conversation or traditional browsing.

## **ğŸ›  Tech Stack**  
| **Category** | **Technologies** |
|-------------|-----------------|
| **Frontend** | React.js, Vite, Tailwind CSS |
| **Backend** | Node.js, Express.js, MongoDB |
| **AI & NLP** | OpenAI GPT-4o-mini, OpenAI Assistant API |
| **Web Scraper** | Puppeteer |
| **Cloud Services** | EC2, CloudFront, S3, ELB, ACM |

---

## **ğŸ“‚ Prerequisites**  

Before running the project, ensure your system meets the following requirements:  

### **1ï¸âƒ£ Install Node.js & Package Manager**  
This project requires **Node.js 18+**. Download from: [Node.js Official Site](https://nodejs.org/en/download/)  

Check your installation:  
```bash
node -v
npm -v
```

We recommend **yarn** for the frontend. Install it globally if you havenâ€™t:  
```bash
npm install -g yarn
```

### **2ï¸âƒ£ Install MongoDB**  
Set up **MongoDB locally** or use **MongoDB Atlas**:  
- [Download MongoDB](https://www.mongodb.com/try/download/community)  
- Start MongoDB:  
  ```bash
  mongod
  ```
  

### **3ï¸âƒ£ Set Up OpenAI API Key**  
Create an OpenAI account and obtain an API key:  
ğŸ”— [Get OpenAI API Key](https://platform.openai.com/signup)  

---

## **ğŸ“¥ Installation**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/minchenlee/Thesis.git
cd shopulse
```

### **2ï¸âƒ£ Configure Environment Variables**  
Create the required `.env` files in the respective directories:  

#### **ğŸ“ Backend (`backend/.env`)**
```env
MONGODB_URL="your-mongodb-url"
OPENAI_API_KEY="your-openai-api-key"
OPENAI_ASSISTANT_ID="your-openai-assistant-id"
PORT=3000
```

#### **ğŸ“ Frontend (`frontend/.env`)**
```env
VITE_API_BASE_URL=http://localhost:3000
```

#### **ğŸ“ Crawler (`crawler/.env`)**
```env
MONGODB_URL="your-mongodb-url"
```

### **3ï¸âƒ£ Install Dependencies**  
Run the following commands inside each directory:  

#### **ğŸ“ Backend**  
```bash
cd backend
npm install
```

#### **ğŸ“ Frontend**  
```bash
cd frontend
yarn install
```

#### **ğŸ“ Crawler (Scraper)**  
```bash
cd crawler
npm install
```

### **4ï¸âƒ£ Populate the Database**  
You can either:  
âœ… **Use the Web Scraper** to collect real-time product data from Amazon and Walmart  
or  
âœ… **Load Sample Data** from `backend/sample.json` into MongoDB

You should notice that this project use the Altas's text search, so you need to create search index first on your Altas's cluster.  
  [Create Search Index](https://docs.atlas.mongodb.com/reference/atlas-search/create-index/)

---

## **ğŸ›  Running the Project**  

Start the **backend and frontend servers**:  

#### **ğŸ“ Backend**  
```bash
npm start
```

#### **ğŸ“ Frontend**  
```bash
yarn run dev
```

---

## **ğŸ”— Demo**  

The prototype is deployed and accessible through the following links. The site will request a **Prolific ID** (a unique user identifier)â€”you can enter any string.  

| **Interface Type** | **Live Demo** | **Preview** |
|-------------------|-------------|------------|
| **Conversational UI (CUI)** | [ğŸ”— View Here](https://shopulse.shop/chat) | ![CUI](https://imgur.com/wWfNv5K.png) |
| **Graphical UI (GUI)** | [ğŸ”— View Here](https://shopulse.shop/gui) | ![GUI](https://imgur.com/ZMr1k9Z.png) |
| **Hybrid UI** | [ğŸ”— View Here](https://shopulse.shop/hybrid) | ![Hybrid UI](https://imgur.com/yaQ4arF.png) |

---

## **ğŸ“œ License**  
This project is for research purposes and is licensed under [MIT License](LICENSE).

